{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick recap of DAY3 discussions:\n",
    "\n",
    "- Functions in Python \n",
    "    - Defining a function \n",
    "    - Passing Arguments\n",
    "    - Return values\n",
    "    - Passing a list\n",
    "    - Passing an arbitrary number of arguments \n",
    "- Creating Modules and Storing your functions in Modules.\n",
    "    - Importing and renaming modules\n",
    "    - Accessing functions stored in modules\n",
    "- Lambda Expressions\n",
    "- Time and DateTime in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..................................................................................\n",
    "### Tuesday, 14th April, 2020\n",
    "# ..................................................................................\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python for Data Science and Machine Learning \n",
    "- Modules and standard Python library\n",
    "- Data Science tools \n",
    "    - Numpy\n",
    "    - Pandas\n",
    "    - Statsmodel\n",
    "    - Matplotlib\n",
    "    - Seaborn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science\n",
    "\n",
    "The amount of data in the world today has grown exponentially due availability of lots of sensors and data-storing technologies everywhere. Leveraging on such enormous information to drive actionable insights is now a source of competitive advantage. Working to drive these insights has ignited interest of many into the field.\n",
    "\n",
    "![image.png](images/ds.jpg)\n",
    "  \n",
    "                  **Data Science is multidisciplinary which combines Coding, Mathematics, Statistics and an expert area of                          application (e.g. Medicine, Finance, Agriculture, Security )**\n",
    "                  \n",
    "\n",
    "**Data science** is a process of using data to understand the world. An attempt to work with data\n",
    "to find answers to questions. Data Science provide tools for:\n",
    "\n",
    "- Data Extraction:\n",
    "\n",
    "Data science is a field about processes and systems, to extract data of forms,whether it is an unstructured or structured form, from various sources\n",
    "\n",
    "- Data Understanding:\n",
    "\n",
    "Just like biological sciences are the study of biology; physical sciences, it's the study of physical reactions. Data is real, data has properties we need to study them to work on them.\n",
    "\n",
    "- Story Telling:\n",
    "\n",
    "Data science is the science of uncovering the insights and trends that are hiding behind data\n",
    "\n",
    "- Decision / Policy Making:\n",
    "\n",
    "With the insights uncovered from data, you can make strategic choices for an organization or institution.\n",
    "\n",
    "\n",
    "\n",
    "####  Data science is a not an art, it is a **science**; It is a not an act, it is a **process**, subjected to evolvement and change in steps. There is no consensus to how things are done, since the insight to be drawn depends solely on the data under consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data could be \n",
    "- structured\n",
    "    - More like tabular data that you're familiar with in Microsoft Excel format, it has rows and columns,\n",
    "- Unstructure\n",
    "    - Mostly gathered from web, where it's not arrange into rows and columns since it's text.\n",
    "    - Sometimes it's video and audio.\n",
    "   \n",
    "   **It might require a little bit more effort to get information out of unstructured data eg Web Scraping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The four Pillars of Data Science\n",
    "1. Data Analysis — turning raw information into knowledge that can be acted upon.\n",
    "    - Domain knowledge — learn the business problem/question and understand accuracy vs cost trade-offs.\n",
    "    - Research — get the data, design experiments and conduct them (hypothesis testing).\n",
    "    - Interpretation — Summarize data, Do Visualization, and show insight from summaries.\n",
    "    \n",
    "2. Data Modelling — machine learning, in order to estimate the data we wish we had.\n",
    "    - Supervised Learning — classification, regression, anomaly detection.\n",
    "    - Unsupervised Learning — clustering, dimensionality reduction, anomaly detection.\n",
    "    - Custom Algorithm Development — feature engineering, numerical optimization.\n",
    "    \n",
    "3. Data Engineering — making everything work faster, more robustly and at greater scale.\n",
    "    - Data Management — database management, pipeline construction, data collection.\n",
    "    - Production — automation, system integration, “robustification”.\n",
    "    - Software Engineering — ensure maintainability, scaling, collaborative development.\n",
    "    \n",
    "4. Data Wrangling — The dirty work of data\n",
    "    - Data Formatting — type conversion, string manipulation, fixing errors.\n",
    "    - Value Interpretation — dates and times, units of measurement, missing values.\n",
    "    - Data Handling — querying, slicing, joining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Career Roles\n",
    "\n",
    "The demand for various data science roles is increasing by the day. The vast range of careers in the data \n",
    "science industry is accompanied by an avalanche of job postings, with designation and descriptions used \n",
    "loosely. Hence, there is a lot of confusion around who does what in the industry.\n",
    "\n",
    "Here is an attempt to help clear some of the confusion. **Please note that this list is not exhaustive**\n",
    "- Data Analyst\n",
    "- Data Scientist\n",
    "- Data Engineer\n",
    "- Machine Learning Engineer\n",
    "- Data Architect\n",
    "- Business Intelligence Analyst\n",
    "- Statistician\n",
    "- Data Administrator\n",
    "\n",
    "#### Data Analyst (‘Data Detective’)\n",
    "- Role:\n",
    "    - Collects, transforms, manipulate and process large data sets to suit the desired analysis of the company\n",
    "- Skills & Talent:\n",
    "    - Spreadsheet tools (e.g. Excel)\n",
    "    - Database systems (SQL and NO SQL based)\n",
    "    - Data Cleaning\n",
    "    - Data Visualization\n",
    "    - Communication and Presentation\n",
    "    - Probability and Statistics\n",
    "\n",
    "\n",
    "#### Data Scientist\n",
    "- Role:\n",
    "    - Data scientists do many of the same things as data analysts, but they also typically build machine learning models to make accurate predictions about the future based on past data.\n",
    "- Skills & Talent:\n",
    "    - All of the skills required of data analyst, plus: \n",
    "    - A solid understanding of both supervised and unsupervised machine learning models and methods\n",
    "    - A strong understanding of statistics and the ability to evaluate statistical models\n",
    "    - More advanced data-science-related programming skills in Python or R, and potentially familiarity with other tools like Apache Spark\n",
    "\n",
    "\n",
    "#### Data Engineer\n",
    "- Role:\n",
    "    - Creates blueprints for data management systems to integrate,centralize, protect and maintain data sources. At a company with a data team, the data engineer might be responsible for building data pipelines to get the latest sales, marketing, and revenue data to data analysts and scientists quickly and in a usable format. They’re also likely responsible for building and maintaining the infrastructure needed to store and quickly access past data.\n",
    "- Skills & Talent:\n",
    "    - Data warehousing solutions\n",
    "    - In-depth knowledge of database architecture\n",
    "    - Extraction Transformation and Load (ETL), spreadsheet and BI tools\n",
    "    - Data modelling\n",
    "    - Data APIs\n",
    "\n",
    "![image.png](images/oppor.jpg)\n",
    "![image.png](images/oppor1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Tools and Libraries in Python\n",
    "\n",
    "- [NUMPY](https://numpy.org/): An extensive collection of high-level mathematical functions and implemented methods to make processing large multidimensional arrays and matrices seamless. It is useful linear algebra, Fourier transform, and random number operations etc\n",
    "\n",
    "- [PANDAS](https://pandas.pydata.org/) pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,built on top of the Python programming language. \n",
    "\n",
    "- [SCIPY](https://scipy.org/scipylib/) Another core library for scientific computing is SciPy. It is based on NumPy and therefore extends its capabilities. SciPy main data structure is again a multidimensional array, implemented by Numpy. The package contains tools that help with solving linear algebra, probability theory, integral calculus and many more tasks. \n",
    "\n",
    "- [STATSMODELS](http://www.statsmodels.org/devel/): A Python module that provides many opportunities for statistical data analysis, such as statistical models estimation, performing statistical tests, etc. With its help, you can implement many machine learning methods and explore different plotting possibilities.\n",
    "\n",
    "#### Visualization\n",
    "- [MATPLOTLIB](https://matplotlib.org/index.html): Matplotlib is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs\n",
    "\n",
    "- [SEABORN](https://seaborn.pydata.org/): Seaborn is essentially a higher-level API based on the matplotlib library. It contains more suitable default settings for processing charts. Also, there is a rich gallery of visualizations including some complex types like time series, jointplots, and violin diagrams.\n",
    "\n",
    "- [PLOTLY](https://plot.ly/python/): Enable users to build interactive reports that are print ready and presentation ready without ever downloading, linking, or reformatting.\n",
    "\n",
    "- [BOKEH](https://bokeh.pydata.org/en/latest/): The Bokeh library creates interactive and scalable visualizations in a browser using JavaScript widgets. The library provides a versatile collection of graphs, styling possibilities, interaction abilities in the form of linking plots, adding widgets, and defining callbacks, and many more useful features.\n",
    "\n",
    "- [PYDOT](https://pypi.org/project/pydot/): Pydot is a library for generating complex oriented and non-oriented graphs. It is an interface to Graphviz, written in pure Python. With its help, it is possible to show the structure of graphs, which are very often needed when building neural networks and decision trees based algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUMPY Example\n",
    "To create an 8 by 7, zero matrix, a user might decide to used a repetitive statement (loop) with list data structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zero matrix using  a normal for loop is .................\n",
      " [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "The zero matrix using  list comprehension is .................\n",
      " [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "##Using a for loop to create array of zeros\n",
    "a = []\n",
    "for x in range(8): #This iterates for the number of rows\n",
    "    row = []\n",
    "    for y in range(7): #This iterates for the number of columns\n",
    "        row.append(0)  #This adds 0 to the list (rows)\n",
    "    a.append(row)      #This the row to the list (a) whhich represents the matrix\n",
    "print ('The zero matrix using  a normal for loop is .................\\n', a)\n",
    "\n",
    "\n",
    "    \n",
    "##Using a for nested loop in list cmprehension to create array of zeros\n",
    "a = [[0 for y in range(7)] for x in range(8)]\n",
    "print ('\\nThe zero matrix using  list comprehension is .................\\n', a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, this is not appropriate as list is a data structure that stores data of different types. If user therefore inputs a letter 'o' instead of 0, the list structure accepts it, though basic matrices operations like addition, subtraction, will be impossible. \n",
    "\n",
    "**NUMPY ARRAY** stores a list of elements that belong to the same data type. Manipulation of stored data becomes easier since basic matrices operations like addition, subtraction, multiplications etc can be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The zero matrix using numpy is .................\n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# An 8 by 7 zero matrix using numpy array\n",
    "\n",
    "import numpy\n",
    "a = numpy.zeros((8,7)) \n",
    "print ('\\nThe zero matrix using numpy is .................\\n', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STATSMODEL Example\n",
    "\n",
    "https://www.statsmodels.org/stable/stats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\ICT\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=9\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>1.351e+32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 22 May 2020</td> <th>  Prob (F-statistic):</th>          <td>3.36e-126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:05:24</td>     <th>  Log-Likelihood:    </th>          <td>  296.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     9</td>      <th>  AIC:               </th>          <td>  -591.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th>          <td>  -591.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.5000</td> <td>  4.3e-17</td> <td> 1.16e+16</td> <td> 0.000</td> <td>    0.500</td> <td>    0.500</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.490</td> <th>  Durbin-Watson:     </th> <td>   0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.475</td> <th>  Jarque-Bera (JB):  </th> <td>   0.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.075</td> <th>  Prob(JB):          </th> <td>   0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.633</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   1.000\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
       "Method:                 Least Squares   F-statistic:                          1.351e+32\n",
       "Date:                Fri, 22 May 2020   Prob (F-statistic):                   3.36e-126\n",
       "Time:                        22:05:24   Log-Likelihood:                          296.75\n",
       "No. Observations:                   9   AIC:                                     -591.5\n",
       "Df Residuals:                       8   BIC:                                     -591.3\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.5000    4.3e-17   1.16e+16      0.000       0.500       0.500\n",
       "==============================================================================\n",
       "Omnibus:                        1.490   Durbin-Watson:                   0.090\n",
       "Prob(Omnibus):                  0.475   Jarque-Bera (JB):                0.709\n",
       "Skew:                          -0.075   Prob(JB):                        0.701\n",
       "Kurtosis:                       1.633   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "X = np.arange(0, 9) * 2\n",
    "y = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Programming Data Science Tools\n",
    "- **[TABLEAU](https://www.tableau.com/)** Tableau can help anyone see and understand their data. Connect to almost any database, drag and drop to create visualizations, and share with a click.\n",
    "\n",
    "- **[POWER BI](https://powerbi.microsoft.com/en-us/)** - Power BI is a business analytics service by Microsoft. It aims to provide interactive visualizations and business intelligence capabilities with an interface simple enough for end users to create their own reports and dashboards.\n",
    "\n",
    "- **[BIG ML](https://bigml.com/)** -  an online machine learning platform. The platform solves and automates classification, regression, cluster analysis, anomaly detection, association discovery, and topic modeling task. BigML, Inc. serves analysts, software developers, and scientists to perform machine learning tasks, transform data into actionable models that are used as remote services or, embedded into applications to make predictions.\n",
    "\n",
    "- **[MICROSOFT AZURE](https://azure.microsoft.com/en-us/)** - Microsoft Azure is a cloud computing service created by Microsoft for building, testing, deploying, and managing applications and services through Microsoft-managed data centers. It provides software as a service, platform as a service and infrastructure as a service and supports many different programming languages, tools, and frameworks, including both Microsoft-specific and third-party software and systems\n",
    "\n",
    "- **KNIME** – This tool is awesome for training machine learning models. It takes some getting used to initially but the GUI is awesome to get started with. It produces results on par with most tools and is free of cost as well\n",
    "\n",
    "- **FeatureLab** – It allows easy predictive modeling and deployment using GUI. One of the best selling points it has is automated feature engineering [For more](https://www.analyticsvidhya.com/blog/2018/05/19-data-science-tools-for-people-dont-understand-coding/)\n",
    "\n",
    "- **MarketSwitch** – This tool is more focussed on optimization rather than predictive analytics\n",
    "\n",
    "- **Logical Glue** – Another GUI based machine learning platform which works from raw data to deployment\n",
    "\n",
    "- **Pure Predictive** – This tool uses a patented Artificial Intelligence system which obviates the part of data preparation and model tuning; it uses AI to combine 1000s of models into what they call “supermodels”\n",
    "\n",
    "- **ATH Precision** – This tool by Analyttica has 600+ analytical functions inbuilt, which are available at a point of a click. ATH Pr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
